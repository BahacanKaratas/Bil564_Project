{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Yzwy621gDC"
      },
      "source": [
        "# BIL564 Derin Öğrenme Projesi – GAN ile Veri Artırımı\n",
        "\n",
        "## Proje Hedefi:\n",
        "Bu notebook'ta GAN (Generative Adversarial Network) mimarisi kullanılarak, IQ-OTH/NCCD akciğer kanseri görüntü veri seti üzerinden **sentetik görüntü üretimi** gerçekleştirilmiştir. GAN ile üretilen bu görüntüler, azınlık sınıfların temsilini güçlendirmek ve CNN modelinin sınıflandırma performansını artırmak amacıyla kullanılmaktadır.\n",
        "\n",
        "## Uygulanan Yöntemler:\n",
        "- **GAN Eğitimi**: Her sınıf (normal, benign, malignant) için ayrı GAN mimarileri oluşturulmuştur.\n",
        "- **Generator & Discriminator**: Giriş olarak rastgele latent vektör alıp sahte görüntüler üretir; discriminator ise bu görüntülerin gerçekliğini değerlendirir.\n",
        "- **Discriminator Tabanlı Filtreleme**: Yalnızca `güven skoru > 0.95` olan sentetik görüntüler eğitimde kullanılmak üzere seçilmiştir.\n",
        "- **Görselleştirme**: Gerçek ve sentetik görüntüler görsel olarak karşılaştırılmış, kalite değerlendirmesi yapılmıştır.\n",
        "\n",
        "## Ana Aşamalar:\n",
        "1. Kaggle üzerinden veri setinin indirilmesi\n",
        "2. Görüntülerin yeniden boyutlandırılması ve TensorFlow dataset'e dönüştürülmesi\n",
        "3. GAN mimarilerinin tanımlanması ve kayıp fonksiyonlarının oluşturulması\n",
        "4. Her sınıf için GAN eğitimi ve sentetik veri üretimi\n",
        "5. Yüksek kaliteli sahte görüntülerin `.png` formatında kaydedilmesi\n",
        "6. Gerçek ve GAN görüntülerinin görselleştirilmesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilIB6U-L-Fwy"
      },
      "source": [
        "## Kaggle Üzerinden Veri Setinin İndirilmesi\n",
        "\n",
        "Bu hücrede Kaggle API kullanılarak IQ-OTHNCCD akciğer kanseri veri seti indirilmektedir.  \n",
        "- `kaggle.json` dosyası yüklenerek API erişimi sağlanır.  \n",
        "- Dataset, çalışma dizinine `.zip` formatında indirilir.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "K5SqSMDB3kW7",
        "outputId": "8d6f260f-d47e-4030-ccae-6c8f84013167"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os, zipfile\n",
        "\n",
        "# 1. kaggle.json dosyasını yükle\n",
        "print(\"Lütfen kaggle.json dosyanı yükle:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2. Kaggle API ayarları\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"wb\") as f:\n",
        "    f.write(uploaded[\"kaggle.json\"])\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
        "\n",
        "# 3. Dataset'i indir (senin verdiğin path)\n",
        "!kaggle datasets download -d hamdallak/the-iqothnccd-lung-cancer-dataset\n",
        "\n",
        "# 4. Zip dosyasını çıkar\n",
        "with zipfile.ZipFile(\"the-iqothnccd-lung-cancer-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"lung_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYT6fcWu-nMS"
      },
      "source": [
        "## Kaggle'dan İndirilen ZIP Dosyasının Açılması\n",
        "\n",
        "Bu hücrede, Kaggle üzerinden indirilen `The IQ-OTHNCCD lung cancer dataset.zip` dosyası çıkarılmaktadır.  \n",
        "- ZIP dosyasının yolu manuel olarak belirtilmiştir.  \n",
        "- İçerikler `/content/lung_dataset` klasörüne açılır.  \n",
        "\n",
        "> Bu adım, verileri eğitimde kullanmak üzere hazır hale getirir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weVaA5yB_5Ey"
      },
      "source": [
        "## Gerekli Kütüphanelerin Yüklenmesi\n",
        "\n",
        "Bu hücrede proje boyunca kullanılacak tüm kütüphaneler içe aktarılmaktadır.  \n",
        "- `TensorFlow` ve `Keras`: GAN, CNN modeli ve veri işleme işlemleri için kullanılır.  \n",
        "- `NumPy`, `Matplotlib`, `PIL`, `os`: Görüntü işleme, dosya yönetimi ve görselleştirme için kullanılır.  \n",
        "- `scikit-learn`: Veri setini eğitim/test olarak ayırmak için kullanılır.  \n",
        "- Kod tekrarı ve karmaşayı önlemek amacıyla gereksiz ve yinelenen importlar temizlenmiştir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v3Dyh2n1gDF",
        "outputId": "ecb5548e-af4b-4cc0-a450-3cbfc6c7f4dc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "import os\n",
        "import imghdr\n",
        "import random\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7yZtuT8bGqB"
      },
      "source": [
        "## Veri Setinin Yüklenmesi ve Ön İşleme\n",
        "\n",
        "Bu hücrede IQ-OTHNCCD akciğer kanseri veri seti TensorFlow `image_dataset_from_directory` fonksiyonu ile yüklenmektedir.\n",
        "\n",
        "### Temel Adımlar:\n",
        "- **Yol Tanımlama:** Görsellerin bulunduğu dizin belirtilmiştir.\n",
        "- **Parametreler:** Görseller 128x128 boyutuna yeniden boyutlandırılmış, batch boyutu 32 olarak ayarlanmıştır.\n",
        "- **Normalization:** Görseller [-1, 1] aralığına normalize edilmiştir (`Rescaling(1./127.5, offset=-1)`).\n",
        "- **Train/Test Ayrımı:** %80 eğitim, %20 doğrulama olarak ayrılmıştır.\n",
        "\n",
        "### Performans Optimizasyonu:\n",
        "- `cache()`, `prefetch()` ve `shuffle()` işlemleri eğitim sürecini hızlandırmak için kullanılmıştır.\n",
        "\n",
        "### Sınıf Bilgisi:\n",
        "- Veri setinde 3 sınıf mevcuttur: **Benign**, **Malignant** ve **Normal**.\n",
        "- Bu sınıflar etiket-dizin eşleşmeleri ile bir sözlükte tutulmaktadır.\n",
        "\n",
        "### Sınıf Bazlı Ayrım:\n",
        "- Eğitim verisi içerisinden her bir sınıf (benign, malignant, normal) için ayrı dataset’ler filtrelenmiştir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_KnwT2nbGGl",
        "outputId": "5ec643bc-0a00-4135-9284-7086656167ee"
      },
      "outputs": [],
      "source": [
        "dataset_path = Path(\"/content/lung_dataset/The IQ-OTHNCCD lung cancer dataset\")\n",
        "\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "seed = 123\n",
        "\n",
        "normalization_layer = Rescaling(1./127.5, offset=-1)\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = normalization_layer(image)\n",
        "    return image, label\n",
        "\n",
        "raw_train_dataset = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "raw_val_dataset = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = raw_train_dataset.class_names\n",
        "print(\"Sınıf İsimleri:\", class_names)\n",
        "\n",
        "train_dataset = (\n",
        "    raw_train_dataset\n",
        "    .map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .shuffle(1000)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_dataset = (\n",
        "    raw_val_dataset\n",
        "    .map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "label_to_index = {name: i for i, name in enumerate(class_names)}\n",
        "print(\"Etiket eşleşmeleri:\", label_to_index)\n",
        "\n",
        "\n",
        "def filter_by_class(dataset, class_index):\n",
        "    return dataset.filter(lambda img, label: tf.reduce_any(tf.equal(label, class_index)))\n",
        "\n",
        "train_dataset_benign = filter_by_class(train_dataset, label_to_index[\"Bengin cases\"])\n",
        "train_dataset_malignant = filter_by_class(train_dataset, label_to_index[\"Malignant cases\"])\n",
        "train_dataset_normal = filter_by_class(train_dataset, label_to_index[\"Normal cases\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XnkJ_B71gDG"
      },
      "source": [
        "## GAN Mimarisi: Generator ve Discriminator\n",
        "\n",
        "### Generator\n",
        "- Giriş: 100 boyutlu rastgele bir latent vektör.\n",
        "- 4 katmanlı transpoz konvolüsyonel yapı ile 128x128 boyutunda RGB görüntüler üretir.\n",
        "- Aktivasyon: `tanh` ile [-1, 1] aralığında normalize edilmiş çıktı verir.\n",
        "\n",
        "### Discriminator\n",
        "- Giriş: 128x128 boyutunda bir görüntü (gerçek veya sahte).\n",
        "- 4 katmanlı konvolüsyonel yapı ve sonrasında `Dense(1)` ile gerçeklik olasılığı tahmini yapar.\n",
        "- Aktivasyon: `sigmoid`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ijCOHeap1gDG",
        "outputId": "71d5ea97-eaaf-4bbe-cedf-b9b20a397b6a"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(16 * 16 * 256, use_bias=False, input_shape=(100,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((16, 16, 256)),\n",
        "\n",
        "        layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False),  # (16->32)\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False),   # (32->64)\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Conv2DTranspose(3, (3, 3), strides=(2, 2), padding='same', activation='tanh')  # (64->128)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        # Input layer accepts 128x128 RGB images\n",
        "        layers.InputLayer(input_shape=(128, 128, 3)),\n",
        "\n",
        "        # First convolution: 128x128 -> 64x64\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        # Second convolution: 64x64 -> 32x32\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        # Third convolution: 32x32 -> 16x16\n",
        "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        # Fourth convolution: 16x16 -> 8x8\n",
        "        layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        # Flatten and output a single probability\n",
        "        layers.Flatten(),  # Output shape: (None, 8*8*512) = (None, 32768)\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Normal GAN\n",
        "gen_normal = build_generator()\n",
        "disc_normal = build_discriminator()\n",
        "\n",
        "# Benign GAN\n",
        "gen_benign = build_generator()\n",
        "disc_benign = build_discriminator()\n",
        "\n",
        "# Malignant GAN\n",
        "gen_malignant = build_generator()\n",
        "disc_malignant = build_discriminator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3e7TAJ0BXIV"
      },
      "source": [
        "## GAN Kayıp Fonksiyonları (Loss Functions)\n",
        "\n",
        "### Discriminator Loss\n",
        "- Gerçek görüntüler için `label=1`, sahte görüntüler için `label=0` hedeflenir.\n",
        "- Gerçek ve sahte görüntüler için ayrı ayrı `BinaryCrossentropy` hesaplanır.\n",
        "- Toplam kayıp: `real_loss + fake_loss`.\n",
        "\n",
        "### Generator Loss\n",
        "- Amaç: Üretilen sahte görüntülerin `Discriminator` tarafından **gerçek** olarak sınıflandırılmasını sağlamaktır.\n",
        "- Bu nedenle, tüm `fake_output`’lar için `label=1` olarak verilir.\n",
        "\n",
        "> `BinaryCrossentropy(from_logits=False)` kullanılmıştır çünkü çıktı aktivasyon fonksiyonu `sigmoid` ile normalize edilmiştir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5KV8LNK1gDG"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_output = tf.cast(real_output, tf.float32)\n",
        "    fake_output = tf.cast(fake_output, tf.float32)\n",
        "\n",
        "    real_labels = tf.ones_like(real_output, dtype=tf.float32)\n",
        "    fake_labels = tf.zeros_like(fake_output, dtype=tf.float32)\n",
        "\n",
        "    real_loss = cross_entropy(real_labels, real_output)\n",
        "    fake_loss = cross_entropy(fake_labels, fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    fake_output = tf.cast(fake_output, tf.float32)\n",
        "    labels = tf.ones_like(fake_output, dtype=tf.float32)\n",
        "    return cross_entropy(labels, fake_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Te_3pa1gDG"
      },
      "source": [
        "### Optimizers\n",
        "\n",
        "- Bu hücrede, hem Generator hem de Discriminator için Adam optimizasyon algoritması tanımlanmıştır. Bu optimizasyon, ağların öğrenme sürecini hızlandırmak ve stabil hale getirmek için kullanılır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GovvWL361gDG"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.AdamW(learning_rate=0.0001, weight_decay=1e-4, beta_1=0.5, beta_2=0.999)\n",
        "discriminator_optimizer = tf.keras.optimizers.AdamW(learning_rate=0.0002, weight_decay=1e-4, beta_1=0.5, beta_2=0.999)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8lNmPzUBxvF"
      },
      "source": [
        "## GAN Eğitim Süreci\n",
        "\n",
        "### `train_step()`:\n",
        "- Bir batch veri alınarak:\n",
        "  - Latent vektör ile sahte görüntüler üretilir.\n",
        "  - Gerçek ve sahte görüntüler `Discriminator` üzerinden geçer.\n",
        "  - Her iki modelin loss değerleri hesaplanır ve geri yayılım (backpropagation) yapılır.\n",
        "\n",
        "---\n",
        "\n",
        "### `train_gan()`:\n",
        "- Verilen epoch sayısı kadar `train_step()` çalıştırılır.\n",
        "- Her `vis_interval` epoch’ta bir sentetik görüntüler oluşturularak görselleştirilir.\n",
        "- Eğitim sonunda:\n",
        "  - Generator ve Discriminator modelleri `.h5` formatında kaydedilir.\n",
        "  - Final sentetik örnekler gösterilir.\n",
        "\n",
        "---\n",
        "\n",
        "### `generate_and_plot_images()`:\n",
        "- Generator ile örnek latent vektörlerden görseller üretilir.\n",
        "- Görseller bir grid şeklinde görselleştirilir (`matplotlib` ile).\n",
        "\n",
        "> Bu yapı, ileride entegre edeceğimiz **Streamlit uygulamasında** da kullanılacak olan temel GAN eğitim mantığını oluşturur.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11ZApEiw1gDG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_step(data, generator, discriminator, generator_optimizer, discriminator_optimizer):\n",
        "    images, _ = data\n",
        "    noise = tf.random.normal([tf.shape(images)[0], 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        dis_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    discriminator_gradients = disc_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, dis_loss\n",
        "\n",
        "\n",
        "def train_gan(dataset, epochs, generator, discriminator, generator_optimizer, discriminator_optimizer, test_images, model_name, vis_interval=5):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        total_gen_loss = 0.0\n",
        "        total_dis_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            gen_loss, dis_loss = train_step(image_batch, generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
        "            total_gen_loss += gen_loss\n",
        "            total_dis_loss += dis_loss\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_gen_loss = total_gen_loss / num_batches\n",
        "        avg_dis_loss = total_dis_loss / num_batches\n",
        "\n",
        "        print(f\"Generator Loss: {avg_gen_loss:.4f}, Discriminator Loss: {avg_dis_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % vis_interval == 0 or epoch == 0:\n",
        "            generate_and_plot_images(generator, test_images, title=f\"{model_name} - Epoch {epoch + 1}\")\n",
        "\n",
        "    print(f\"\\n✅ Eğitim tamamlandı: {model_name}\")\n",
        "    generate_and_plot_images(generator, test_images, title=f\"{model_name} - Final\")\n",
        "    generator.save(f\"{model_name}_generator.h5\")\n",
        "    discriminator.save(f\"{model_name}_discriminator.h5\")\n",
        "    print(f\"💾 Kaydedildi: {model_name}_generator.h5, {model_name}_discriminator.h5\")\n",
        "\n",
        "\n",
        "def generate_and_plot_images(generator, test_images, title=\"GAN Görüntüleri\"):\n",
        "    generated_images = generator(test_images, training=False)\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    grid_size = int(np.sqrt(generated_images.shape[0]))\n",
        "\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(grid_size, grid_size, i + 1)\n",
        "        plt.imshow((generated_images[i].numpy() + 1) / 2)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMK2FQmU1gDG"
      },
      "source": [
        "## GAN Eğitiminin Başlatılması\n",
        "\n",
        "### Sabit Test Gürültüsü\n",
        "- Eğitim sırasında görsellerin dönemsel olarak üretilebilmesi için 16 adet sabit latent vektör (`test_images`) oluşturulmuştur.\n",
        "\n",
        "\n",
        "###  `run_training()` Fonksiyonu\n",
        "- Belirtilen veri kümesi için:\n",
        "  - Yeni bir **Generator** ve **Discriminator** oluşturulur.\n",
        "  - `AdamW` optimizasyon algoritması ile her iki model eğitilir.\n",
        "  - Eğitim `train_gan()` fonksiyonu ile yürütülür.\n",
        "  - Klavye ile eğitim durdurulursa modeller geçici olarak kaydedilir (`checkpoint`).\n",
        "\n",
        "---\n",
        "\n",
        "### Çoklu GAN Eğitimi\n",
        "- Her sınıf (Normal, Benign, Malignant) için ayrı GAN modelleri eğitilebilir.\n",
        "- Şu anda yalnızca **Malignant** sınıfı için eğitim başlatılmıştır:\n",
        "\n",
        "```python\n",
        "run_training(train_dataset_malignant, \"gan_malignant\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VbVomeLm1gDH",
        "outputId": "1a88c733-a204-4946-b19c-23364e5fd4cc"
      },
      "outputs": [],
      "source": [
        "# Sabit test gürültüleri\n",
        "noise_dimensions = 100\n",
        "num_test_images = 16\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "test_images = tf.random.normal([num_test_images, noise_dimensions])\n",
        "\n",
        "# GPU için ayar (opsiyonel)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Eğitim fonksiyonu çağrısı\n",
        "def run_training(dataset, model_name):\n",
        "    generator = build_generator()\n",
        "    discriminator = build_discriminator()\n",
        "\n",
        "    generator_optimizer = tf.keras.optimizers.AdamW(learning_rate=0.00015, weight_decay=1e-4, beta_1=0.5, beta_2=0.999)\n",
        "    discriminator_optimizer = tf.keras.optimizers.AdamW(learning_rate=0.0001, weight_decay=1e-4, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "    try:\n",
        "        train_gan(\n",
        "            dataset=dataset,\n",
        "            epochs=3000,\n",
        "            generator=generator,\n",
        "            discriminator=discriminator,\n",
        "            generator_optimizer=generator_optimizer,\n",
        "            discriminator_optimizer=discriminator_optimizer,\n",
        "            test_images=test_images,\n",
        "            model_name=model_name\n",
        "        )\n",
        "    except KeyboardInterrupt:\n",
        "        print(f\"\\n Eğitim durduruldu: {model_name}\")\n",
        "        generator.save(f\"{model_name}_generator_interrupted.h5\")\n",
        "        discriminator.save(f\"{model_name}_discriminator_interrupted.h5\")\n",
        "        print(\"💾 Checkpoint kaydedildi.\")\n",
        "\n",
        "\n",
        "# GAN eğitimini başlat\n",
        "run_training(train_dataset_normal, \"gan_normal\")\n",
        "run_training(train_dataset_benign, \"gan_benign\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#İleri aşamalarda buraya gerek olmadığını analiz ettim\n",
        "\n",
        "#run_training(train_dataset_malignant, \"gan_malignant\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5JPp30OCh8o"
      },
      "source": [
        "## GAN ile Sentetik Görüntü Üretimi ve Kaydedilmesi (Tüm Sınıflar)\n",
        "\n",
        "Bu hücre, daha önce eğitilmiş GAN modelleri (`gan_benign.h5`, `gan_malignant.h5`, `gan_normal.h5`) kullanılarak **her bir sınıf için 400 adet sentetik görüntü** üretmek amacıyla çalıştırılır.\n",
        "\n",
        "### İşlem Adımları:\n",
        "1. **Model Yükleme:** İlgili sınıfa ait GAN modeli `.h5` uzantısıyla yüklenir.\n",
        "2. **Latent Boyutu:** Modelin giriş şekli (`latent_dim`) otomatik olarak algılanır.\n",
        "3. **Latent Vektör Oluşturma:** `z ∼ N(0, 1)` dağılımından istenilen sayıda örnek üretilir.\n",
        "4. **Görüntü Üretimi:** Generator model kullanılarak sentetik görüntüler elde edilir.\n",
        "5. **Görüntü Kaydı:**\n",
        "   - Görüntüler normalize edilip (0–255 aralığına getirilip), `.png` olarak uygun klasöre kaydedilir.\n",
        "   - Örn: `generated_images_benign/`, `generated_images_malignant/`, `generated_images_normal/`\n",
        "\n",
        "> Bu işlem her sınıf için ayrı ayrı çalıştırılmalıdır. Üretilen görüntüler, CNN modeli için veri setini genişletmede (augmentation) kullanılacaktır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKLGRLSv2aP-",
        "outputId": "15aca5ce-513a-4f78-fcd3-1910777d1347"
      },
      "outputs": [],
      "source": [
        "generator = load_model(\"gan_benign_generator.h5\")\n",
        "\n",
        "\n",
        "input_shape = generator.input_shape\n",
        "latent_dim = input_shape[1]\n",
        "\n",
        "print(f\"[INFO] Detected latent dimension: {latent_dim}\")\n",
        "\n",
        "\n",
        "output_dir = \"generated_benign_normal\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "num_images = 1000\n",
        "latent_vectors = np.random.normal(0, 1, (num_images, latent_dim))\n",
        "\n",
        "\n",
        "generated_images = generator.predict(latent_vectors, verbose=1)\n",
        "\n",
        "\n",
        "for i, img in enumerate(generated_images):\n",
        "\n",
        "    img = np.clip(img, 0, 1)\n",
        "\n",
        "\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "    if img.shape[-1] == 1:\n",
        "        img = img.squeeze(-1)\n",
        "\n",
        "\n",
        "    plt.imsave(f\"{output_dir}/image_{i+1:03d}.png\", img, cmap='gray' if len(img.shape) == 2 else None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEYqaJpXEHFj"
      },
      "source": [
        "## Gerçek ve GAN Görüntülerinin Karşılaştırmalı Görselleştirmesi\n",
        "### Görselleştirilen Sınıflar:\n",
        "- Normal cases\n",
        "- Benign cases\n",
        "\n",
        "### Adımlar:\n",
        "1. Her sınıf için:\n",
        "   - `num_samples` kadar **gerçek** ve **sentetik** görüntü rastgele seçilir.\n",
        "2. Görseller bir subplot grid içerisinde yan yana yerleştirilir:\n",
        "   - Sol sütunlar: Gerçek görüntüler.\n",
        "   - Sağ sütunlar: GAN tarafından üretilmiş sentetik görüntüler.\n",
        "\n",
        "> Bu karşılaştırma, GAN modellerinin görsel kalitesini değerlendirmek ve üretimlerinin gerçek görüntülere ne kadar yakın olduğunu gözlemlemek için önemlidir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "qGIs--pX3oQu",
        "outputId": "105f4aa6-eb57-4854-9446-3a2122dfed07"
      },
      "outputs": [],
      "source": [
        "classes = [\"Normal cases\", \"Bengin cases\"]\n",
        "num_samples = 5\n",
        "\n",
        "real_base_path = \"/content/lung_dataset/The IQ-OTHNCCD lung cancer dataset\"\n",
        "gan_base_paths = {\n",
        "    \"Normal cases\": \"generated_images_normal\",\n",
        "    \"Bengin cases\": \"generated_images_benign\"\n",
        "}\n",
        "\n",
        "fig, axs = plt.subplots(len(classes), num_samples * 2, figsize=(num_samples * 2.5, len(classes) * 3))\n",
        "\n",
        "for row_idx, class_name in enumerate(classes):\n",
        "\n",
        "    real_path = os.path.join(real_base_path, class_name)\n",
        "    gan_path = gan_base_paths[class_name]\n",
        "\n",
        "    real_images = random.sample(os.listdir(real_path), num_samples)\n",
        "    gan_images = random.sample(os.listdir(gan_path), num_samples)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "\n",
        "        real_img = Image.open(os.path.join(real_path, real_images[i]))\n",
        "        axs[row_idx, i].imshow(real_img, cmap='gray' if real_img.mode == 'L' else None)\n",
        "        axs[row_idx, i].axis('off')\n",
        "        axs[row_idx, i].set_title(f\"{class_name} - Real\", fontsize=8)\n",
        "\n",
        "\n",
        "        gan_img = Image.open(os.path.join(gan_path, gan_images[i]))\n",
        "        axs[row_idx, num_samples + i].imshow(gan_img, cmap='gray' if gan_img.mode == 'L' else None)\n",
        "        axs[row_idx, num_samples + i].axis('off')\n",
        "        axs[row_idx, num_samples + i].set_title(f\"{class_name} - GAN\", fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (tensorflow_env)",
      "language": "python",
      "name": "tensorflow_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
